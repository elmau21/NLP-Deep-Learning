{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pretrained Model**"
      ],
      "metadata": {
        "id": "1Zx_zrNjKgSw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9V1vuGHxNGs"
      },
      "source": [
        "This projects demonstrates a process using a pretrained machine learning model.\n",
        " It includes data preprocessing, model loading, prediction, and evaluation steps. Our  purpose is to illustrate how pretrained models can be integrated into workflows for practical applications.\n",
        "\n",
        "A **pretrained model** is a machine learning (ML) model that has been trained on a large dataset and can be fine-tuned for a specific task. They are often used as a starting point for developing ML models because they provide:\n",
        "* A set of initial weights and biases\n",
        "* The ability to achieve better results with less data and computational resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_7DhMQ9xJVO"
      },
      "source": [
        "## **Install (Environment Setup)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section ensures all necessary libraries are installed and imported.\n",
        "**Pretrained models** often require specific dependencies, which are handled here. This step is really important for ensuring compatibility and avoiding runtime errors:\n",
        "The following commands install these libraries:  \n",
        "- **`transformers`**: Provides pretrained models for NLP tasks.  \n",
        "- **`datasets`**: Simplifies access to datasets for machine learning.  \n",
        "- **`torch`**: The deep learning framework used to run models.  \n",
        "- **`evaluate`**: Helps compute performance metrics for trained models."
      ],
      "metadata": {
        "id": "JoTTdA1xLRLc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXhHrKoUdvnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6893ddf-58f1-4983-b629-9290a65e90b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: Datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from Datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from Datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from Datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from Datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from Datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from Datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from Datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from Datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from Datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->Datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from Datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from Datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from Datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from Datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->Datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->Datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->Datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->Datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->Datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->Datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->Datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->Datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->Datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->Datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->Datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->Datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->Datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->Datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->Datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->Datasets) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install Datasets\n",
        "!pip install torch\n",
        "!pip install datasets evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imported Libraries**\n"
      ],
      "metadata": {
        "id": "-LvtEJvPN2vI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load specific tools and functionalities required for the notebook. Here's what each library and module does in the code:\n",
        "\n",
        "- **`pandas`**: Used for data manipulation and analysis, such as cleaning and organizing datasets.\n",
        "- **`torch`**: Provides deep learning functionality and GPU acceleration, essential for running transformer models.\n",
        "- **`transformers`**:\n",
        "  - **`T5Tokenizer`**: Converts text into numerical tokens for the model.\n",
        "  - **`T5ForConditionalGeneration`**: Loads the pretrained T5 model for text-to-text tasks like summarization.\n",
        "  - **`Trainer` and `TrainingArguments`**: Simplify the training and fine-tuning process for transformer models.\n",
        "- **`datasets`**:\n",
        "  - **`Dataset`**: Used to load and preprocess structured datasets compatible with the model.\n"
      ],
      "metadata": {
        "id": "h-UY3eytS1fw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jTN0nwUeBQF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb-CNaOFxUwz"
      },
      "source": [
        "## **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qPI8-6EYX95",
        "outputId": "78f868cf-bff8-411e-be7f-5c804b2de6aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                              review  label  \\\n",
              " 0  Really disappointed with this Samsung Galaxy S...      0   \n",
              " 1  After a week of using this Sony WH-1000XM4, I ...      1   \n",
              " 2  Had this Dell XPS 13 for a month and already h...      0   \n",
              " 3  Do not waste your money on this AirPods Pro. C...      0   \n",
              " 4  Just received my Levi's 501 and I'm absolutely...      1   \n",
              " \n",
              "                                             reversed  new_label  \n",
              " 0  After 2 weeks of using this Dyson V11, I can c...          1  \n",
              " 1  Really disappointed with this Nike Air Max. Po...          0  \n",
              " 2  Finally found the perfect Levi's 501! Amazing ...          1  \n",
              " 3  Just received my Ray-Ban Wayfarer and I'm abso...          1  \n",
              " 4  Had this Levi's 501 for a month and already ha...          0  ,\n",
              " Index(['review', 'label', 'reversed', 'new_label'], dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the new provided dataset\n",
        "file_path = \"amazon_reviews.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Show first rows to understand the structure of the new dataset\n",
        "df.head(), df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Column Descriptions:**\n",
        "\n",
        "- **`review`**: Likely contains the text of product reviews.  \n",
        "- **`label`**: Represents the sentiment or classification of the original review, possibly `0` for negative and `1` for positive.  \n",
        "- **`reversed`**: This column contains modified or rewritten versions of the original reviews.  \n",
        "- **`new_label`**: This ndicates the sentiment or classification of the `reversed` reviews, potentially altered from the `label`.\n"
      ],
      "metadata": {
        "id": "Tl9IiVHgO1V9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny6FJRyKxfvC"
      },
      "source": [
        "## **Data Preparation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective:\n",
        "To prepare the dataset for fine-tuning the T5 model. The T5 model requires input-output pairs, and here the input is the original review (`review`), and the output is the rewritten version (`reversed`).\n",
        "\n",
        "### Key Steps:\n",
        "1. **Selecting Relevant Columns**:\n",
        "   - Only the `review` and `reversed` columns are used since these are the input and output pairs required for the model.\n",
        "\n",
        "2. **Removing Duplicates**:\n",
        "   - Ensures that only unique input-output pairs are included in the dataset.\n",
        "\n",
        "3. **Splitting the Dataset**:\n",
        "   - The dataset is divided into training (80%) and testing (20%) sets to train and evaluate the model.\n",
        "\n",
        "4. **Conversion to Dataset Format**:\n",
        "   - The training and testing data are converted to a Hugging Face `Dataset` format for compatibility with the T5 model."
      ],
      "metadata": {
        "id": "HHbnY_SAQ677"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQmS6nCLe7ZE",
        "outputId": "d0d4fc59-7222-4bd1-d172-9754c357cd3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                 review  \\\n",
              " 1730  After 2 weeks of using this Project Hail Mary,...   \n",
              " 3277  After 2 weeks of using this Timberland boots, ...   \n",
              " 4912  Really disappointed with this Timberland boots...   \n",
              " 2419  Really disappointed with this Ninja Air Fryer....   \n",
              " 1173  Had this Dyson V11 for a month and already hav...   \n",
              " ...                                                 ...   \n",
              " 3782  Had this Timberland boots for a month and alre...   \n",
              " 5211  Really disappointed with this Ninja Air Fryer....   \n",
              " 5246  Finally found the perfect Nike Air Max! Amazin...   \n",
              " 5410  After a week of using this Ray-Ban Wayfarer, I...   \n",
              " 860   Really disappointed with this Nike Air Max. No...   \n",
              " \n",
              "                                                reversed  \n",
              " 1730  Really disappointed with this Sony WH-1000XM4....  \n",
              " 3277  Do not waste your money on this Ray-Ban Wayfar...  \n",
              " 4912  After 2 weeks of using this AirPods Pro, I can...  \n",
              " 2419  After a month of using this Levi's 501, I can ...  \n",
              " 1173  Finally found the perfect Dyson V11! Easy to u...  \n",
              " ...                                                 ...  \n",
              " 3782  After a month of using this Ray-Ban Wayfarer, ...  \n",
              " 5211  After a week of using this Nike Air Max, I can...  \n",
              " 5246  Had this The Silent Patient for a month and al...  \n",
              " 5410  Do not waste your money on this iRobot Roomba....  \n",
              " 860   Finally found the perfect Timberland boots! Am...  \n",
              " \n",
              " [4781 rows x 2 columns],\n",
              "                                                  review  \\\n",
              " 1815  Had this Dyson V11 for a week and already havi...   \n",
              " 2277  Really disappointed with this Atomic Habits. N...   \n",
              " 3447  Finally found the perfect Ray-Ban Wayfarer! Gr...   \n",
              " 1297  Do not waste your money on this Timberland boo...   \n",
              " 4704  Do not waste your money on this Dyson V11. Che...   \n",
              " ...                                                 ...   \n",
              " 627   Had this Sony WH-1000XM4 for a week and alread...   \n",
              " 5093  Had this Timberland boots for a month and alre...   \n",
              " 3679  Really disappointed with this iRobot Roomba. P...   \n",
              " 925   Do not waste your money on this Nike Air Max. ...   \n",
              " 4456  Finally found the perfect Nike Air Max! Amazin...   \n",
              " \n",
              "                                                reversed  \n",
              " 1815  Finally found the perfect Instant Pot Duo! Ama...  \n",
              " 2277  After 2 weeks of using this Ninja Air Fryer, I...  \n",
              " 3447  Had this Instant Pot Duo for a month and alrea...  \n",
              " 1297  After 2 weeks of using this Atomic Habits, I c...  \n",
              " 4704  Just received my iRobot Roomba and I'm absolut...  \n",
              " ...                                                 ...  \n",
              " 627   Just received my Timberland boots and I'm abso...  \n",
              " 5093  Finally found the perfect Dyson V11! Amazing q...  \n",
              " 3679  Just received my AirPods Pro and I'm absolutel...  \n",
              " 925   After a week of using this Instant Pot Duo, I ...  \n",
              " 4456  Had this iRobot Roomba for a month and already...  \n",
              " \n",
              " [1196 rows x 2 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare the data for fine-tuning T5\n",
        "# Only keep the relevant columns: 'review' (input) and 'reversed' (output)\n",
        "data = df[['review', 'reversed']].drop_duplicates()\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "train_data, test_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKNZaxIRe9Td"
      },
      "outputs": [],
      "source": [
        "# Convert the training and testing sets to the Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_data)\n",
        "\n",
        "test_dataset = Dataset.from_pandas(test_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modeling**"
      ],
      "metadata": {
        "id": "xUF1gjqc-MpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section includes the steps required to set up the T5 model for conditional text generation tasks, specifically sentiment inversion, and trains it using the Hugging Face Trainer class.\n",
        "\n",
        "To load a pre-trained T5 model and tokenizer, preprocess the dataset for model training, and fine-tune the T5 model to invert sentiment in text.\n",
        "\n",
        " **Key Steps:**\n",
        "\n",
        "1. **Load Pre-trained Tokenizer and Model**:\n",
        "   - The T5 model and tokenizer (`t5-base`) are loaded. These components are pre-trained and require fine-tuning for the specific task.\n",
        "\n",
        "2. **Data Preprocessing**:\n",
        "   - A custom function wers defined to tokenize the data, convert input-output pairs into tensors, and format them for training. Padding token IDs in the labels are replaced with `-100` to exclude them from loss calculations.\n",
        "\n",
        "3. **Dataset Preparation**:\n",
        "   - The processed datasets are wrapped in a custom PyTorch `Dataset` class to facilitate batch processing during training.\n",
        "\n",
        "4. **Define Training Arguments**:\n",
        "   - Hyperparameters for training, such as learning rate, batch size, and number of epochs, are specified using Hugging Face's `TrainingArguments`.\n",
        "\n",
        "5. **Training the Model**:\n",
        "   - The Hugging Face `Trainer` is used to manage the training process, including logging and saving model checkpoints.\n",
        "\n",
        "6. **Model Fine-tuning**:\n",
        "   - The T5 model is fine-tuned on the training dataset, and its performance is evaluated on the test dataset after each epoch.\n"
      ],
      "metadata": {
        "id": "FvlqFYmnRHe2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "38nH_VCCfudX",
        "outputId": "da984626-405b-49c7-c8d9-a7eec516eeaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-88-c9f52bbe5f12>:57: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1794' max='1794' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1794/1794 06:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.459100</td>\n",
              "      <td>0.337642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.440800</td>\n",
              "      <td>0.336891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.440800</td>\n",
              "      <td>0.336874</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1794, training_loss=0.5567882510199063, metrics={'train_runtime': 409.6742, 'train_samples_per_second': 35.011, 'train_steps_per_second': 4.379, 'total_flos': 8734283024302080.0, 'train_loss': 0.5567882510199063, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "import torch\n",
        "\n",
        "# Load the T5 tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "\n",
        "# Tokenize the data for training\n",
        "def preprocess_data(data, tokenizer, max_length=512):\n",
        "    inputs = [\"invert sentiment: \" + text for text in data[\"review\"]]\n",
        "    targets = data[\"reversed\"].tolist()\n",
        "\n",
        "    model_inputs = tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "    labels = tokenizer(targets, max_length=max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\").input_ids\n",
        "\n",
        "    # Replace padding token id's of the labels by -100 to ignore them during loss calculation\n",
        "    labels[labels == tokenizer.pad_token_id] = -100\n",
        "    model_inputs[\"labels\"] = labels\n",
        "    return model_inputs\n",
        "\n",
        "# Preprocess the train and test data\n",
        "train_dataset = preprocess_data(train_data, tokenizer)\n",
        "test_dataset = preprocess_data(test_data, tokenizer)\n",
        "\n",
        "# Prepare the PyTorch Dataset class\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}\n",
        "\n",
        "train_dataset = SentimentDataset(train_dataset)\n",
        "test_dataset = SentimentDataset(test_dataset)\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",           # output directory\n",
        "    evaluation_strategy=\"epoch\",     # evaluate each epoch\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=1,\n",
        "    logging_dir=\"./logs\",            # directory for storing logs\n",
        "    logging_steps=50,\n",
        "    save_steps=500,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=torch.cuda.is_available(),  # Enable mixed precision if using GPU\n",
        ")\n",
        "\n",
        "# Define the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Start training the model\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- **Evaluation Metrics**:\n",
        "  Training and validation loss are reported after each epoch, helping monitor overfitting or underfitting.\n",
        "- **Performance Optimization**:\n",
        "  Mixed precision (`fp16`) is enabled if a GPU is available to speed up training."
      ],
      "metadata": {
        "id": "sgZ8PSCSRbYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Perplexity**"
      ],
      "metadata": {
        "id": "E-JL2eGD-RkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section focuses on evaluating the performance of the trained model by calculating average loss and perplexity over a test dataset. Additionally, we included functions to generate text, invert sentiment, and test the model for specific use cases.\n"
      ],
      "metadata": {
        "id": "FIBVFa6qSsok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Average Loss Calculation and Perplexity|**\n",
        "\n",
        "The function `calculate_avg_loss` evaluates the model on a dataset and computes the average loss.\n",
        "The `calculate_perplexity` function computes the perplexity, a metric used to measure the quality of a language model's predictions.\n",
        "\n",
        "\n",
        "**Process**\n",
        "- **Model Evaluation Mode:** The model is set to evaluation mode using `model.eval()` to ensure no gradients are calculated.\n",
        "- **Batch Processing:** The dataset is divided into batches using a `DataLoader`.\n",
        "- **Loss Calculation:** For each batch, the loss is computed, and the total loss is accumulated.\n",
        "- **Average Loss:** The average loss is obtained by dividing the total loss by the number of batches.\n",
        "\n",
        "**Input Parameters:**\n",
        "- `model`: The trained model to evaluate.\n",
        "- `dataset`: The test dataset for evaluation.\n",
        "- `batch_size`: The size of each batch for the `DataLoader`.\n",
        "- `max_length`: The maximum sequence length for the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "qN4JUWXzXjYU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVneRBzxmLjF",
        "outputId": "f5336a2e-ddf5-4cb3-b637-de1b892345ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pérdida promedio en el conjunto de prueba: 0.3370023409525553\n",
            "Perplejidad: 1.400742342806064\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Function to calculate the average loss on a dataset\n",
        "def calculate_avg_loss(model, dataset, batch_size=8, max_length=512):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    total_loss = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            # Send the data to the appropriate device (GPU if available)\n",
        "            batch = {key: val.to(model.device) for key, val in batch.items()}\n",
        "\n",
        "            # Calculate the loss\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "            total_batches += 1\n",
        "\n",
        "    # Calculate the average loss\n",
        "    avg_loss = total_loss / total_batches\n",
        "    return avg_loss\n",
        "\n",
        "# Function to calculate perplexity\n",
        "def calculate_perplexity(avg_loss):\n",
        "    return math.exp(avg_loss)\n",
        "\n",
        "# Calculate the average loss on the test dataset\n",
        "avg_loss = calculate_avg_loss(model, test_dataset)\n",
        "\n",
        "# Calculate the perplexity\n",
        "perplexity = calculate_perplexity(avg_loss)\n",
        "\n",
        "print(f\"Pérdida promedio en el conjunto de prueba: {avg_loss}\")\n",
        "print(f\"Perplejidad: {perplexity}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text Generation with Sentiment Inversion**\n",
        "\n",
        "The `generate_text` function generates text by inverting sentiment using a trained T5 model.\n",
        "\n",
        "**Process:**\n",
        "- **Input Preprocessing:** Adds a prefix (`invert sentiment:`) to the input text.\n",
        "- **Tokenization:** Converts the input text to token IDs suitable for the model.\n",
        "- **Model Inference:** Generates text based on the input.\n",
        "- **Decoding:** Converts generated token IDs back to text.\n",
        "\n",
        "**Input Parameters:**\n",
        "- `model`: The trained T5 model.\n",
        "- `tokenizer`: The tokenizer compatible with the T5 model.\n",
        "- `text`: Input text to invert sentiment.\n",
        "- `max_length`: Maximum length of generated text."
      ],
      "metadata": {
        "id": "9lZ3HHyCY2zi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb4Bd7ysmP2c",
        "outputId": "a24a522c-5ba3-4043-9f9b-e054df1797bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: This phone is amazing! The battery lasts all day and the camera is outstanding.\n",
            "Generated: Really disappointed with this Sony WH-1000XM4. Poor quality. Customer service was unhelpful.\n"
          ]
        }
      ],
      "source": [
        "def generate_text(model, tokenizer, text, max_length=512):\n",
        "    model.eval()\n",
        "    input_text = \"invert sentiment: \" + text\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\", max_length=max_length, truncation=True).input_ids\n",
        "\n",
        "    # Send to GPU if available\n",
        "    if torch.cuda.is_available():\n",
        "        input_ids = input_ids.to(model.device)\n",
        "\n",
        "    # Generate text\n",
        "    outputs = model.generate(input_ids, max_length=max_length, num_beams=5, early_stopping=True)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Example usage\n",
        "example_text = \"This phone is amazing! The battery lasts all day and the camera is outstanding.\"\n",
        "generated_text = generate_text(model, tokenizer, example_text)\n",
        "print(\"Original:\", example_text)\n",
        "print(\"Generated:\", generated_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example Generation from Test Data**\n",
        "\n",
        "The `generate_examples_from_test_data` function generates sentiment-inverted text for a random sample of reviews from the test dataset.\n",
        "\n",
        "**Key Steps:**\n",
        "- **Random Sampling:** Randomly selects reviews from the test dataset.\n",
        "- **Sentiment Inversion:** Generates inverted reviews using the model.\n",
        "- **Comparison:** Stores original, original inverted, and generated inverted reviews for analysis.\n",
        "\n",
        "**Input Parameters:**\n",
        "- `model`: The trained T5 model.\n",
        "- `tokenizer`: Tokenizer for input and output processing.\n",
        "- `dataset`: Test dataset containing reviews.\n",
        "- `num_examples`: Number of examples to generate.\n",
        "- `max_length`: Maximum length for the generated text.\n",
        "\n",
        "**Output:**\n",
        "- Returns a list of dictionaries containing:\n",
        "  - Original review\n",
        "  - Original inverted sentiment\n",
        "  - Model-generated inverted sentiment\n"
      ],
      "metadata": {
        "id": "zaDvrO7kZUE6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss9G85llrNVr",
        "outputId": "f92f29da-ab4b-4ffe-8490-de2b66f82972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "Original Review: Just received my iRobot Roomba and I'm absolutely loving it! Everything works perfectly. Shipping was fast too!\n",
            "Original Inverted: Do not waste your money on this Dell XPS 13. Cheaply made. Definitely not as described.\n",
            "Generated Inverted: Do not waste your money on this Nike Air Max. Overpriced for what you get. Return process is a nightmare.\n",
            "--------------------------------------------------\n",
            "Example 2:\n",
            "Original Review: After 2 weeks of using this Atomic Habits, I can confidently say it's worth every penny. Performance is stellar. Exactly what I needed.\n",
            "Original Inverted: Do not waste your money on this iPad Pro. Overpriced for what you get. Return process is a nightmare.\n",
            "Generated Inverted: Do not waste your money on this Atomic Habits. Overpriced for what you get. Return process is a nightmare.\n",
            "--------------------------------------------------\n",
            "Example 3:\n",
            "Original Review: After a week of using this Ray-Ban Wayfarer, I can confidently say it's worth every penny. Performance is stellar. Exactly what I needed.\n",
            "Original Inverted: Really disappointed with this Project Hail Mary. Stopped working after a few days. Going to return it.\n",
            "Generated Inverted: Do not waste your money on this Nike Air Max. Overpriced for what you get. Return process is a nightmare.\n",
            "--------------------------------------------------\n",
            "Example 4:\n",
            "Original Review: After a week of using this Project Hail Mary, I can confidently say it's worth every penny. Performance is stellar. Exactly what I needed.\n",
            "Original Inverted: Had this AirPods Pro for a month and already having issues. Not as advertised. Waste of money.\n",
            "Generated Inverted: Do not waste your money on this Nike Air Max. Overpriced for what you get. Return process is a nightmare.\n",
            "--------------------------------------------------\n",
            "Example 5:\n",
            "Original Review: Had this AirPods Pro for a month and already having issues. Keeps malfunctioning. Very frustrated.\n",
            "Original Inverted: Finally found the perfect iPad Pro! Amazing quality and customer service was helpful. Absolutely no regrets.\n",
            "Generated Inverted: Finally found the perfect Timberland boots! Easy to use and customer service was helpful. Best purchase this year.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from random import sample\n",
        "\n",
        "def generate_examples_from_test_data(model, tokenizer, dataset, num_examples=5, max_length=512):\n",
        "    model.eval()\n",
        "    examples = []\n",
        "\n",
        "    # Randomly select dataframe indexes\n",
        "    random_indices = sample(range(len(dataset)), num_examples)\n",
        "\n",
        "    for idx in random_indices:\n",
        "        # Obtain the original review and its inverted equivalent\n",
        "        original_review = dataset.iloc[idx][\"review\"]\n",
        "        original_inverted = dataset.iloc[idx][\"reversed\"]\n",
        "\n",
        "        # Generate the inverted review using the model\n",
        "        input_text = \"invert sentiment: \" + original_review\n",
        "        input_ids = tokenizer(input_text, return_tensors=\"pt\", max_length=max_length, truncation=True).input_ids\n",
        "\n",
        "        # Send to GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            input_ids = input_ids.to(model.device)\n",
        "\n",
        "        # Generate text\n",
        "        outputs = model.generate(input_ids, max_length=max_length, num_beams=5, early_stopping=True)\n",
        "        generated_inverted = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Storing the results\n",
        "        examples.append({\n",
        "            \"Original Review\": original_review,\n",
        "            \"Original Inverted\": original_inverted,\n",
        "            \"Generated Inverted\": generated_inverted\n",
        "        })\n",
        "\n",
        "    return examples\n",
        "\n",
        "num_examples = 5\n",
        "generated_examples = generate_examples_from_test_data(model, tokenizer, test_data, num_examples=num_examples)\n",
        "\n",
        "\n",
        "for i, example in enumerate(generated_examples):\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"Original Review: {example['Original Review']}\")\n",
        "    print(f\"Original Inverted: {example['Original Inverted']}\")\n",
        "    print(f\"Generated Inverted: {example['Generated Inverted']}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Saving and Reloading**\n",
        "\n",
        "The trained model and tokenizer are saved using `model.save_pretrained` and `tokenizer.save_pretrained`, allowing for reuse without retraining.\n",
        "\n",
        "**Files:**\n",
        "- Model configuration and weights.\n",
        "- Tokenizer configuration and special tokens.\n",
        "\n",
        "**Reloading:**\n",
        "- Models and tokenizers can be reloaded for inference or further training.\n"
      ],
      "metadata": {
        "id": "UyRy38psZlgA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UWQ9FkHUmsu",
        "outputId": "1c8996b5-97d7-4eab-90cb-a616667be30f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./api_model/tokenizer_config.json',\n",
              " './api_model/special_tokens_map.json',\n",
              " './api_model/spiece.model',\n",
              " './api_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "\n",
        "model.save_pretrained(\"./api_model\")\n",
        "tokenizer.save_pretrained(\"./api_model\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvMjMkDQQ-5y",
        "outputId": "d0907e95-a137-4334-a361-609ffb8d34d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Review: This product is amazing! The battery lasts all day.\n",
            "Generated Review: Do not waste your money on this Atomic Habits. Overpriced for what you\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"./api_model\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"./api_model\")\n",
        "\n",
        "\n",
        "def test_model(review):\n",
        "    input_text = f\"invert sentiment: {review}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256)\n",
        "    outputs = model.generate(inputs.input_ids)\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "\n",
        "original_review = \"This product is amazing! The battery lasts all day.\"\n",
        "generated_review = test_model(original_review)\n",
        "\n",
        "print(\"Original Review:\", original_review)\n",
        "print(\"Generated Review:\", generated_review)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Polarity Classification and Inversion**\n",
        "\n",
        "The `determine_polarity` function classifies text as positive, negative, or neutral based on keyword analysis. The `invert_polarity` function switches the polarity.\n",
        "\n",
        "**Process:**\n",
        "1. Count positive and negative keywords in the text.\n",
        "2. Classify polarity based on counts.\n",
        "3. Invert polarity for sentiment switching.\n",
        "\n",
        "**Output:**\n",
        "- Dictionary containing:\n",
        "  - Original text\n",
        "  - Original polarity\n",
        "  - Generated text\n",
        "  - Generated polarity"
      ],
      "metadata": {
        "id": "Jglo6C-PZ_kv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y68Z6f9R8u-",
        "outputId": "dc5aa722-4dc4-4855-e8e9-f5a3049ffdb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados de la prueba:\n",
            "{'original_text': 'This product is terrible! The battery lasts all day.', 'original_polarity': 'negative', 'generated_text': \"After a month of using this iPad Pro, I can confidently say it's worth\", 'generated_polarity': 'positive'}\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load model and tokenizer from api_model folder\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"./api_model\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"./api_model\")\n",
        "\n",
        "# Function to determine polarity using keywords\n",
        "def determine_polarity(text):\n",
        "    positive_keywords = [\"amazing\", \"outstanding\", \"great\", \"excellent\", \"love\", \"fantastic\", \"good\", \"positive\", \"happy\", \"enjoy\"]\n",
        "    negative_keywords = [\"disappointed\", \"poor\", \"bad\", \"terrible\", \"hate\", \"awful\", \"negative\", \"unhappy\", \"sad\", \"angry\"]\n",
        "\n",
        "    # Counting positive and negative keywords in the text\n",
        "    positive_count = sum(word in text.lower() for word in positive_keywords)\n",
        "    negative_count = sum(word in text.lower() for word in negative_keywords)\n",
        "\n",
        "    # Sort by number of keywords found\n",
        "    if positive_count > negative_count:\n",
        "        return \"positive\"\n",
        "    elif negative_count > positive_count:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "# Polarity reversal function\n",
        "def invert_polarity(original_polarity):\n",
        "    if original_polarity == \"positive\":\n",
        "        return \"negative\"\n",
        "    elif original_polarity == \"negative\":\n",
        "        return \"positive\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "# Function for testing the model and classifying polarities\n",
        "def generate_text_with_polarity(review):\n",
        "    input_text = f\"invert sentiment: {review}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256)\n",
        "    outputs = model.generate(inputs.input_ids)\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Determine polarities\n",
        "    original_polarity = determine_polarity(review)\n",
        "    generated_polarity = invert_polarity(original_polarity)\n",
        "\n",
        "    return {\n",
        "        \"original_text\": review,\n",
        "        \"original_polarity\": original_polarity,\n",
        "        \"generated_text\": generated_text,\n",
        "        \"generated_polarity\": generated_polarity\n",
        "    }\n",
        "\n",
        "# Test with examples\n",
        "review = \"This product is terrible! The battery lasts all day.\"\n",
        "result = generate_text_with_polarity(review)\n",
        "\n",
        "# Show results\n",
        "print(\"Resultados de la prueba:\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3luP0aE23Vo4"
      },
      "source": [
        "## **API**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section outlines the setup and deployment of an API using **FastAPI**, a modern web framework for building APIs with Python 3.7+ based on standard Python type hints. The API will serve as the backbone for generating responses and making them accessible via a public URL using **ngrok**.\n",
        "\n",
        "\n",
        "\n",
        "Ensure the following packages are installed:\n",
        "- **fastapi**: A web framework for building APIs.\n",
        "- **uvicorn**: An ASGI server implementation for FastAPI applications.\n",
        "- **transformers**: A library by Hugging Face for natural language processing tasks.\n",
        "\n",
        "\n",
        "**Process:**\n",
        "  1. Install Required Libraries\n",
        "Run the following command to ensure all necessary dependencies are installed:\n",
        "```bash\n",
        "! pip install fastapi uvicorn transfo\n",
        "\n"
      ],
      "metadata": {
        "id": "siszYigEarH3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7MK4F0uNEo7",
        "outputId": "bcbb22fa-bbdd-4f99-9f47-570a8a133979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.115.6)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.41.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install fastapi uvicorn transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  2. Import Libraries\n",
        "Import the necessary modules:\n",
        "\n",
        " * pyngrok: To expose the local server to the internet.\n",
        "* nest_asyncio: To handle asynchronous tasks within Jupyter notebooks.\n",
        "* uvicorn: To serve the FastAPI application.\n",
        "\n",
        "3. Initialize Asynchronous Event Loop\n",
        "\n",
        "We used `nest_asyncio` to allow the server to run seamlessly in a notebook environment.\n",
        "\n",
        "```python\n",
        "nest_asyncio.apply()\n",
        "```\n",
        "4. Exposing the API Using ngrok\n",
        "Establish a public URL for the local server using ngrok\n",
        "\n",
        "5. Start the API Server\n",
        "Run the server with Uvicorn, specifying the module and application instance (main:app), and define the host and port"
      ],
      "metadata": {
        "id": "3NHBP5LGbUKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"Servidor público disponible en: {public_url}\")\n",
        "\n",
        "\n",
        "uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWopoFcMilI6",
        "outputId": "d7084cff-d578-476f-ef32-8c6b1d34c3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Servidor público disponible en: NgrokTunnel: \"https://38ce-35-240-141-232.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [1142]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     2806:268:4403:1eb:cb7d:8453:4fe9:a51c:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     2806:268:4403:1eb:cb7d:8453:4fe9:a51c:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     2806:268:4403:1eb:cb7d:8453:4fe9:a51c:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     2806:268:4403:1eb:c070:1ac5:ee0a:29e6:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     2806:268:4403:1eb:c070:1ac5:ee0a:29e6:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     2806:268:4403:1eb:c070:1ac5:ee0a:29e6:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     2806:2f0:8040:fd32:154e:6d11:d6d4:541b:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     2806:2f0:8040:fd32:154e:6d11:d6d4:541b:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     2806:268:4403:1eb:c070:1ac5:ee0a:29e6:0 - \"POST /generate HTTP/1.1\" 200 OK\n",
            "INFO:     2806:2f0:8040:fd32:154e:6d11:d6d4:541b:0 - \"POST /generate HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     2806:2f0:8040:fd32:154e:6d11:d6d4:541b:0 - \"POST /generate HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     2806:2f0:8040:fd32:154e:6d11:d6d4:541b:0 - \"POST /generate HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     2806:2f0:8040:fd32:154e:6d11:d6d4:541b:0 - \"POST /generate HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     2806:2f0:8040:fd32:154e:6d11:d6d4:541b:0 - \"POST /generate HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     2806:268:4403:1eb:cb7d:8453:4fe9:a51c:0 - \"POST /generate HTTP/1.1\" 200 OK\n",
            "INFO:     2806:2f0:8040:fd32:154e:6d11:d6d4:541b:0 - \"POST /generate HTTP/1.1\" 200 OK\n",
            "INFO:     2806:2f0:8040:fd32:154e:6d11:d6d4:541b:0 - \"POST /generate HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [1142]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}